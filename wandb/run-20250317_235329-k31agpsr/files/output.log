Original model structure:
Network_1(
  (quant): QuantStub()
  (dequant): DeQuantStub()
  (in_c): Sequential(
    (0): Conv2dNormActivation(
      (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (1): Conv2dNormActivation(
      (0): Conv2d(8, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
  )
  (stages): Sequential(
    (s1): Sequential(
      (b1): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
      (b2): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
      (b3): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential(
          (0): AvgPool2d(kernel_size=3, stride=(1, 2), padding=1)
          (1): Sequential()
        )
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 2), padding=(1, 1), groups=64, bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
    )
    (s2): Sequential(
      (b4): Block(
        (after_block_activation): ReLU()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), groups=64, bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(64, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
      (b5): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(56, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(120, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
    )
    (s3): Sequential(
      (b6): Block(
        (after_block_activation): ReLU()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(56, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(120, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
    )
  )
  (feed_forward): Sequential(
    (0): Conv2d(104, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): AdaptiveAvgPool2d(output_size=(1, 1))
  )
)
Before fusing, in_c module:
Sequential(
  (0): Conv2dNormActivation(
    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (1): Conv2dNormActivation(
    (0): Conv2d(8, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
)
Fusing in_c module index 0 with keys: ['0', '1', '2']
Fusing in_c module index 1 with keys: ['0', '1', '2']
Before fusing, block b1:
Block(
  (after_block_activation): ReLU()
  (shortcut): Sequential()
  (block): Sequential(
    (0): Conv2dNormActivation(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (1): Conv2dNormActivation(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (2): Conv2dNormActivation(
      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (ff): FloatFunctional(
    (activation_post_process): Identity()
  )
)
Fusing block b1 submodule 0 with keys: ['0', '1', '2']
Fusing block b1 submodule 1 with keys: ['0', '1', '2']
Fusing block b1 submodule 2 with keys: ['0', '1']
Before fusing, block b2:
Block(
  (after_block_activation): ReLU()
  (shortcut): Sequential()
  (block): Sequential(
    (0): Conv2dNormActivation(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (1): Conv2dNormActivation(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (2): Conv2dNormActivation(
      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (ff): FloatFunctional(
    (activation_post_process): Identity()
  )
)
Fusing block b2 submodule 0 with keys: ['0', '1', '2']
Fusing block b2 submodule 1 with keys: ['0', '1', '2']
Fusing block b2 submodule 2 with keys: ['0', '1']
Before fusing, block b3:
Block(
  (after_block_activation): ReLU()
  (shortcut): Sequential(
    (0): AvgPool2d(kernel_size=3, stride=(1, 2), padding=1)
    (1): Sequential()
  )
  (block): Sequential(
    (0): Conv2dNormActivation(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (1): Conv2dNormActivation(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 2), padding=(1, 1), groups=64, bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (2): Conv2dNormActivation(
      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (ff): FloatFunctional(
    (activation_post_process): Identity()
  )
)
Fusing block b3 submodule 0 with keys: ['0', '1', '2']
Fusing block b3 submodule 1 with keys: ['0', '1', '2']
Fusing block b3 submodule 2 with keys: ['0', '1']
Before fusing, block b4:
Block(
  (after_block_activation): ReLU()
  (block): Sequential(
    (0): Conv2dNormActivation(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (1): Conv2dNormActivation(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), groups=64, bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (2): Conv2dNormActivation(
      (0): Conv2d(64, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (ff): FloatFunctional(
    (activation_post_process): Identity()
  )
)
Fusing block b4 submodule 0 with keys: ['0', '1', '2']
Fusing block b4 submodule 1 with keys: ['0', '1', '2']
Fusing block b4 submodule 2 with keys: ['0', '1']
Before fusing, block b5:
Block(
  (after_block_activation): ReLU()
  (shortcut): Sequential()
  (block): Sequential(
    (0): Conv2dNormActivation(
      (0): Conv2d(56, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (1): Conv2dNormActivation(
      (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)
      (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (2): Conv2dNormActivation(
      (0): Conv2d(120, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (ff): FloatFunctional(
    (activation_post_process): Identity()
  )
)
Fusing block b5 submodule 0 with keys: ['0', '1', '2']
Fusing block b5 submodule 1 with keys: ['0', '1', '2']
Fusing block b5 submodule 2 with keys: ['0', '1']
Before fusing, block b6:
Block(
  (after_block_activation): ReLU()
  (block): Sequential(
    (0): Conv2dNormActivation(
      (0): Conv2d(56, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (1): Conv2dNormActivation(
      (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)
      (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (2): Conv2dNormActivation(
      (0): Conv2d(120, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (ff): FloatFunctional(
    (activation_post_process): Identity()
  )
)
Fusing block b6 submodule 0 with keys: ['0', '1', '2']
Fusing block b6 submodule 1 with keys: ['0', '1', '2']
Fusing block b6 submodule 2 with keys: ['0', '1']
After fusing, model structure:
Network_1(
  (quant): QuantStub()
  (dequant): DeQuantStub()
  (in_c): Sequential(
    (0): Conv2dNormActivation(
      (0): ConvReLU2d(
        (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): ReLU()
      )
      (1): Identity()
      (2): Identity()
    )
    (1): Conv2dNormActivation(
      (0): ConvReLU2d(
        (0): Conv2d(8, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): ReLU()
      )
      (1): Identity()
      (2): Identity()
    )
  )
  (stages): Sequential(
    (s1): Sequential(
      (b1): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
            (1): Identity()
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
      (b2): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
            (1): Identity()
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
      (b3): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential(
          (0): AvgPool2d(kernel_size=3, stride=(1, 2), padding=1)
          (1): Sequential()
        )
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 2), padding=(1, 1), groups=64)
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
            (1): Identity()
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
    )
    (s2): Sequential(
      (b4): Block(
        (after_block_activation): ReLU()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), groups=64)
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(64, 56, kernel_size=(1, 1), stride=(1, 1))
            (1): Identity()
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
      (b5): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(56, 120, kernel_size=(1, 1), stride=(1, 1))
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120)
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(120, 56, kernel_size=(1, 1), stride=(1, 1))
            (1): Identity()
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
    )
    (s3): Sequential(
      (b6): Block(
        (after_block_activation): ReLU()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(56, 120, kernel_size=(1, 1), stride=(1, 1))
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120)
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(120, 104, kernel_size=(1, 1), stride=(1, 1))
            (1): Identity()
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
    )
  )
  (feed_forward): Sequential(
    (0): Conv2d(104, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): AdaptiveAvgPool2d(output_size=(1, 1))
  )
)
Starting QAT training...
Epoch [1/5], Loss: 2.5556
Epoch [2/5], Loss: 2.1894
Epoch [3/5], Loss: 2.1129
Epoch [4/5], Loss: 2.0349
Epoch [5/5], Loss: 1.9520
Quantized model:
Network_1(
  (quant): Quantize(scale=tensor([0.1832]), zero_point=tensor([62]), dtype=torch.quint8)
  (dequant): DeQuantize()
  (in_c): Sequential(
    (0): Conv2dNormActivation(
      (0): QuantizedConvReLU2d(1, 8, kernel_size=(3, 3), stride=(2, 2), scale=0.0820985659956932, zero_point=0, padding=(1, 1))
      (1): Identity()
      (2): Identity()
    )
    (1): Conv2dNormActivation(
      (0): QuantizedConvReLU2d(8, 32, kernel_size=(3, 3), stride=(2, 2), scale=0.08390136063098907, zero_point=0, padding=(1, 1))
      (1): Identity()
      (2): Identity()
    )
  )
  (stages): Sequential(
    (s1): Sequential(
      (b1): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(32, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.13167093694210052, zero_point=0)
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.1397918164730072, zero_point=0, padding=(1, 1), groups=64)
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): QuantizedConv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), scale=0.22697043418884277, zero_point=63)
            (1): Identity()
          )
        )
        (ff): QFunctional(
          scale=0.24342802166938782, zero_point=56
          (activation_post_process): Identity()
        )
      )
      (b2): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(32, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.14921905100345612, zero_point=0)
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.2046809196472168, zero_point=0, padding=(1, 1), groups=64)
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): QuantizedConv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), scale=0.36302119493484497, zero_point=61)
            (1): Identity()
          )
        )
        (ff): QFunctional(
          scale=0.33409368991851807, zero_point=55
          (activation_post_process): Identity()
        )
      )
      (b3): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential(
          (0): AvgPool2d(kernel_size=3, stride=(1, 2), padding=1)
          (1): Sequential()
        )
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(32, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.14349429309368134, zero_point=0)
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 2), scale=0.18364672362804413, zero_point=0, padding=(1, 1), groups=64)
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): QuantizedConv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), scale=0.2396685630083084, zero_point=60)
            (1): Identity()
          )
        )
        (ff): QFunctional(
          scale=0.31659266352653503, zero_point=36
          (activation_post_process): Identity()
        )
      )
    )
    (s2): Sequential(
      (b4): Block(
        (after_block_activation): ReLU()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(32, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.1817365139722824, zero_point=0)
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(2, 1), scale=0.22788017988204956, zero_point=0, padding=(1, 1), groups=64)
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): QuantizedConv2d(64, 56, kernel_size=(1, 1), stride=(1, 1), scale=0.2974027991294861, zero_point=69)
            (1): Identity()
          )
        )
        (ff): QFunctional(
          scale=1.0, zero_point=0
          (activation_post_process): Identity()
        )
      )
      (b5): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(56, 120, kernel_size=(1, 1), stride=(1, 1), scale=0.2010747343301773, zero_point=0)
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(120, 120, kernel_size=(3, 3), stride=(1, 1), scale=0.19711989164352417, zero_point=0, padding=(1, 1), groups=120)
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): QuantizedConv2d(120, 56, kernel_size=(1, 1), stride=(1, 1), scale=0.26545804738998413, zero_point=67)
            (1): Identity()
          )
        )
        (ff): QFunctional(
          scale=0.2671690285205841, zero_point=55
          (activation_post_process): Identity()
        )
      )
    )
    (s3): Sequential(
      (b6): Block(
        (after_block_activation): ReLU()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(56, 120, kernel_size=(1, 1), stride=(1, 1), scale=0.1874515861272812, zero_point=0)
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(120, 120, kernel_size=(3, 3), stride=(1, 1), scale=0.4084877669811249, zero_point=0, padding=(1, 1), groups=120)
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): QuantizedConv2d(120, 104, kernel_size=(1, 1), stride=(1, 1), scale=0.3982643783092499, zero_point=77)
            (1): Identity()
          )
        )
        (ff): QFunctional(
          scale=1.0, zero_point=0
          (activation_post_process): Identity()
        )
      )
    )
  )
  (feed_forward): Sequential(
    (0): QuantizedConv2d(104, 10, kernel_size=(1, 1), stride=(1, 1), scale=1.1779659986495972, zero_point=55, bias=False)
    (1): QuantizedBatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): AdaptiveAvgPool2d(output_size=(1, 1))
  )
)







Batch: 8/116 -- Batch Accuracy: 25/256
Traceback (most recent call last):
  File "c:\Users\fenel\Documents\dcase2024_task1_baseline\qat_1.py", line 501, in <module>
    main()
  File "c:\Users\fenel\Documents\dcase2024_task1_baseline\qat_1.py", line 477, in main
    quantized_accuracy = evaluate(model_int8, test_loader, MelSpecGenerator)
  File "c:\Users\fenel\Documents\dcase2024_task1_baseline\qat_1.py", line 330, in evaluate
    for idx, batch in enumerate(dataloader):
  File "C:\Users\fenel\anaconda3\envs\d24_t1\lib\site-packages\torch\utils\data\dataloader.py", line 630, in __next__
    data = self._next_data()
  File "C:\Users\fenel\anaconda3\envs\d24_t1\lib\site-packages\torch\utils\data\dataloader.py", line 673, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "C:\Users\fenel\anaconda3\envs\d24_t1\lib\site-packages\torch\utils\data\_utils\fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\Users\fenel\anaconda3\envs\d24_t1\lib\site-packages\torch\utils\data\_utils\fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "c:\Users\fenel\Documents\dcase2024_task1_baseline\dataset\dcase24.py", line 67, in __getitem__
    x, file, label, device, city = self.dataset[self.available_indices[index]]
  File "c:\Users\fenel\Documents\dcase2024_task1_baseline\dataset\dcase24.py", line 45, in __getitem__
    sig, _ = torchaudio.load(os.path.join(dataset_dir, self.files[index]))
  File "C:\Users\fenel\anaconda3\envs\d24_t1\lib\site-packages\torchaudio\_backend\utils.py", line 205, in load
    return backend.load(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)
  File "C:\Users\fenel\anaconda3\envs\d24_t1\lib\site-packages\torchaudio\_backend\soundfile.py", line 27, in load
    return soundfile_backend.load(uri, frame_offset, num_frames, normalize, channels_first, format)
  File "C:\Users\fenel\anaconda3\envs\d24_t1\lib\site-packages\torchaudio\_backend\soundfile_backend.py", line 221, in load
    with soundfile.SoundFile(filepath, "r") as file_:
  File "C:\Users\fenel\anaconda3\envs\d24_t1\lib\site-packages\soundfile.py", line 658, in __init__
    self._file = self._open(file, mode_int, closefd)
  File "C:\Users\fenel\anaconda3\envs\d24_t1\lib\site-packages\soundfile.py", line 1205, in _open
    file_ptr = openfunction(file, mode_int, self._info)
KeyboardInterrupt