Original model structure:
Network_1(
  (quant): QuantStub()
  (dequant): DeQuantStub()
  (in_c): Sequential(
    (0): Conv2dNormActivation(
      (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (1): Conv2dNormActivation(
      (0): Conv2d(8, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
  )
  (stages): Sequential(
    (s1): Sequential(
      (b1): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
      (b2): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
      (b3): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential(
          (0): AvgPool2d(kernel_size=3, stride=(1, 2), padding=1)
          (1): Sequential()
        )
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 2), padding=(1, 1), groups=64, bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
    )
    (s2): Sequential(
      (b4): Block(
        (after_block_activation): ReLU()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), groups=64, bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(64, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
      (b5): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(56, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(120, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
    )
    (s3): Sequential(
      (b6): Block(
        (after_block_activation): ReLU()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(56, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(120, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
    )
  )
  (feed_forward): Sequential(
    (0): Conv2d(104, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): AdaptiveAvgPool2d(output_size=(1, 1))
  )
)
Before fusing, in_c module:
Sequential(
  (0): Conv2dNormActivation(
    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (1): Conv2dNormActivation(
    (0): Conv2d(8, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
)
Fusing in_c module index 0 with keys: ['0', '1', '2']
Fusing in_c module index 1 with keys: ['0', '1', '2']
Before fusing, block b1:
Block(
  (after_block_activation): ReLU()
  (shortcut): Sequential()
  (block): Sequential(
    (0): Conv2dNormActivation(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (1): Conv2dNormActivation(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (2): Conv2dNormActivation(
      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (ff): FloatFunctional(
    (activation_post_process): Identity()
  )
)
Fusing block b1 submodule 0 with keys: ['0', '1', '2']
Fusing block b1 submodule 1 with keys: ['0', '1', '2']
Fusing block b1 submodule 2 with keys: ['0', '1']
Before fusing, block b2:
Block(
  (after_block_activation): ReLU()
  (shortcut): Sequential()
  (block): Sequential(
    (0): Conv2dNormActivation(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (1): Conv2dNormActivation(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (2): Conv2dNormActivation(
      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (ff): FloatFunctional(
    (activation_post_process): Identity()
  )
)
Fusing block b2 submodule 0 with keys: ['0', '1', '2']
Fusing block b2 submodule 1 with keys: ['0', '1', '2']
Fusing block b2 submodule 2 with keys: ['0', '1']
Before fusing, block b3:
Block(
  (after_block_activation): ReLU()
  (shortcut): Sequential(
    (0): AvgPool2d(kernel_size=3, stride=(1, 2), padding=1)
    (1): Sequential()
  )
  (block): Sequential(
    (0): Conv2dNormActivation(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (1): Conv2dNormActivation(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 2), padding=(1, 1), groups=64, bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (2): Conv2dNormActivation(
      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (ff): FloatFunctional(
    (activation_post_process): Identity()
  )
)
Fusing block b3 submodule 0 with keys: ['0', '1', '2']
Fusing block b3 submodule 1 with keys: ['0', '1', '2']
Fusing block b3 submodule 2 with keys: ['0', '1']
Before fusing, block b4:
Block(
  (after_block_activation): ReLU()
  (block): Sequential(
    (0): Conv2dNormActivation(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (1): Conv2dNormActivation(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), groups=64, bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (2): Conv2dNormActivation(
      (0): Conv2d(64, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (ff): FloatFunctional(
    (activation_post_process): Identity()
  )
)
Fusing block b4 submodule 0 with keys: ['0', '1', '2']
Fusing block b4 submodule 1 with keys: ['0', '1', '2']
Fusing block b4 submodule 2 with keys: ['0', '1']
Before fusing, block b5:
Block(
  (after_block_activation): ReLU()
  (shortcut): Sequential()
  (block): Sequential(
    (0): Conv2dNormActivation(
      (0): Conv2d(56, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (1): Conv2dNormActivation(
      (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)
      (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (2): Conv2dNormActivation(
      (0): Conv2d(120, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (ff): FloatFunctional(
    (activation_post_process): Identity()
  )
)
Fusing block b5 submodule 0 with keys: ['0', '1', '2']
Fusing block b5 submodule 1 with keys: ['0', '1', '2']
Fusing block b5 submodule 2 with keys: ['0', '1']
Before fusing, block b6:
Block(
  (after_block_activation): ReLU()
  (block): Sequential(
    (0): Conv2dNormActivation(
      (0): Conv2d(56, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (1): Conv2dNormActivation(
      (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)
      (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (2): Conv2dNormActivation(
      (0): Conv2d(120, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (ff): FloatFunctional(
    (activation_post_process): Identity()
  )
)
Fusing block b6 submodule 0 with keys: ['0', '1', '2']
Fusing block b6 submodule 1 with keys: ['0', '1', '2']
Fusing block b6 submodule 2 with keys: ['0', '1']
After fusing, model structure:
Network_1(
  (quant): QuantStub()
  (dequant): DeQuantStub()
  (in_c): Sequential(
    (0): Conv2dNormActivation(
      (0): ConvReLU2d(
        (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): ReLU()
      )
      (1): Identity()
      (2): Identity()
    )
    (1): Conv2dNormActivation(
      (0): ConvReLU2d(
        (0): Conv2d(8, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): ReLU()
      )
      (1): Identity()
      (2): Identity()
    )
  )
  (stages): Sequential(
    (s1): Sequential(
      (b1): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
            (1): Identity()
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
      (b2): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
            (1): Identity()
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
      (b3): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential(
          (0): AvgPool2d(kernel_size=3, stride=(1, 2), padding=1)
          (1): Sequential()
        )
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 2), padding=(1, 1), groups=64)
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
            (1): Identity()
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
    )
    (s2): Sequential(
      (b4): Block(
        (after_block_activation): ReLU()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), groups=64)
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(64, 56, kernel_size=(1, 1), stride=(1, 1))
            (1): Identity()
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
      (b5): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(56, 120, kernel_size=(1, 1), stride=(1, 1))
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120)
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(120, 56, kernel_size=(1, 1), stride=(1, 1))
            (1): Identity()
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
    )
    (s3): Sequential(
      (b6): Block(
        (after_block_activation): ReLU()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(56, 120, kernel_size=(1, 1), stride=(1, 1))
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120)
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(120, 104, kernel_size=(1, 1), stride=(1, 1))
            (1): Identity()
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
    )
  )
  (feed_forward): Sequential(
    (0): Conv2d(104, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): AdaptiveAvgPool2d(output_size=(1, 1))
  )
)
Starting QAT training...
Epoch [1/5], Loss: 2.5971
Epoch [2/5], Loss: 2.2032
Epoch [3/5], Loss: 2.1224
Epoch [4/5], Loss: 2.0427
Epoch [5/5], Loss: 1.9600
Quantized model:
Network_1(
  (quant): Quantize(scale=tensor([0.1842]), zero_point=tensor([62]), dtype=torch.quint8)
  (dequant): DeQuantize()
  (in_c): Sequential(
    (0): Conv2dNormActivation(
      (0): QuantizedConvReLU2d(1, 8, kernel_size=(3, 3), stride=(2, 2), scale=0.08170097321271896, zero_point=0, padding=(1, 1))
      (1): Identity()
      (2): Identity()
    )
    (1): Conv2dNormActivation(
      (0): QuantizedConvReLU2d(8, 32, kernel_size=(3, 3), stride=(2, 2), scale=0.07888572663068771, zero_point=0, padding=(1, 1))
      (1): Identity()
      (2): Identity()
    )
  )
  (stages): Sequential(
    (s1): Sequential(
      (b1): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(32, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.1213204488158226, zero_point=0)
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.14140290021896362, zero_point=0, padding=(1, 1), groups=64)
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): QuantizedConv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), scale=0.22542604804039001, zero_point=65)
            (1): Identity()
          )
        )
        (ff): QFunctional(
          scale=0.2398182451725006, zero_point=56
          (activation_post_process): Identity()
        )
      )
      (b2): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(32, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.12265655398368835, zero_point=0)
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.18796202540397644, zero_point=0, padding=(1, 1), groups=64)
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): QuantizedConv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), scale=0.34416818618774414, zero_point=64)
            (1): Identity()
          )
        )
        (ff): QFunctional(
          scale=0.31957191228866577, zero_point=58
          (activation_post_process): Identity()
        )
      )
      (b3): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential(
          (0): AvgPool2d(kernel_size=3, stride=(1, 2), padding=1)
          (1): Sequential()
        )
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(32, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.13526999950408936, zero_point=0)
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 2), scale=0.16853022575378418, zero_point=0, padding=(1, 1), groups=64)
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): QuantizedConv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), scale=0.20766998827457428, zero_point=70)
            (1): Identity()
          )
        )
        (ff): QFunctional(
          scale=0.26966023445129395, zero_point=45
          (activation_post_process): Identity()
        )
      )
    )
    (s2): Sequential(
      (b4): Block(
        (after_block_activation): ReLU()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(32, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.14103493094444275, zero_point=0)
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(2, 1), scale=0.17673161625862122, zero_point=0, padding=(1, 1), groups=64)
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): QuantizedConv2d(64, 56, kernel_size=(1, 1), stride=(1, 1), scale=0.22106587886810303, zero_point=71)
            (1): Identity()
          )
        )
        (ff): QFunctional(
          scale=1.0, zero_point=0
          (activation_post_process): Identity()
        )
      )
      (b5): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(56, 120, kernel_size=(1, 1), stride=(1, 1), scale=0.12506213784217834, zero_point=0)
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(120, 120, kernel_size=(3, 3), stride=(1, 1), scale=0.16165201365947723, zero_point=0, padding=(1, 1), groups=120)
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): QuantizedConv2d(120, 56, kernel_size=(1, 1), stride=(1, 1), scale=0.26419901847839355, zero_point=67)
            (1): Identity()
          )
        )
        (ff): QFunctional(
          scale=0.27534621953964233, zero_point=53
          (activation_post_process): Identity()
        )
      )
    )
    (s3): Sequential(
      (b6): Block(
        (after_block_activation): ReLU()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(56, 120, kernel_size=(1, 1), stride=(1, 1), scale=0.14678041636943817, zero_point=0)
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(120, 120, kernel_size=(3, 3), stride=(1, 1), scale=0.3643472194671631, zero_point=0, padding=(1, 1), groups=120)
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): QuantizedConv2d(120, 104, kernel_size=(1, 1), stride=(1, 1), scale=0.387912392616272, zero_point=75)
            (1): Identity()
          )
        )
        (ff): QFunctional(
          scale=1.0, zero_point=0
          (activation_post_process): Identity()
        )
      )
    )
  )
  (feed_forward): Sequential(
    (0): QuantizedConv2d(104, 10, kernel_size=(1, 1), stride=(1, 1), scale=1.0719186067581177, zero_point=63, bias=False)
    (1): QuantizedBatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): AdaptiveAvgPool2d(output_size=(1, 1))
  )
)
evaluate mel_spec, tensor shape: torch.Size([256, 1, 256, 65])
evaluate mel_spec, tensor shape: torch.Size([256, 1, 256, 65])
evaluate mel_spec, tensor shape: torch.Size([256, 1, 256, 65])
evaluate mel_spec, tensor shape: torch.Size([256, 1, 256, 65])
evaluate mel_spec, tensor shape: torch.Size([256, 1, 256, 65])
evaluate mel_spec, tensor shape: torch.Size([256, 1, 256, 65])
evaluate mel_spec, tensor shape: torch.Size([256, 1, 256, 65])
evaluate mel_spec, tensor shape: torch.Size([256, 1, 256, 65])
evaluate mel_spec, tensor shape: torch.Size([256, 1, 256, 65])
evaluate mel_spec, tensor shape: torch.Size([256, 1, 256, 65])
evaluate mel_spec, tensor shape: torch.Size([256, 1, 256, 65])
evaluate mel_spec, tensor shape: torch.Size([256, 1, 256, 65])
evaluate mel_spec, tensor shape: torch.Size([256, 1, 256, 65])

evaluate mel_spec, tensor shape: torch.Size([256, 1, 256, 65])
evaluate mel_spec, tensor shape: torch.Size([256, 1, 256, 65])
Batch: 15/116 -- Batch Accuracy: 23/256
Traceback (most recent call last):
  File "c:\Users\fenel\Documents\dcase2024_task1_baseline\qat_1.py", line 502, in <module>
    main()
  File "c:\Users\fenel\Documents\dcase2024_task1_baseline\qat_1.py", line 478, in main
    quantized_accuracy = evaluate(model_int8, test_loader, MelSpecGenerator)
  File "c:\Users\fenel\Documents\dcase2024_task1_baseline\qat_1.py", line 330, in evaluate
    for idx, batch in enumerate(dataloader):
  File "C:\Users\fenel\anaconda3\envs\d24_t1\lib\site-packages\torch\utils\data\dataloader.py", line 630, in __next__
    data = self._next_data()
  File "C:\Users\fenel\anaconda3\envs\d24_t1\lib\site-packages\torch\utils\data\dataloader.py", line 673, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "C:\Users\fenel\anaconda3\envs\d24_t1\lib\site-packages\torch\utils\data\_utils\fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\Users\fenel\anaconda3\envs\d24_t1\lib\site-packages\torch\utils\data\_utils\fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "c:\Users\fenel\Documents\dcase2024_task1_baseline\dataset\dcase24.py", line 67, in __getitem__
    x, file, label, device, city = self.dataset[self.available_indices[index]]
  File "c:\Users\fenel\Documents\dcase2024_task1_baseline\dataset\dcase24.py", line 45, in __getitem__
    sig, _ = torchaudio.load(os.path.join(dataset_dir, self.files[index]))
  File "C:\Users\fenel\anaconda3\envs\d24_t1\lib\site-packages\torchaudio\_backend\utils.py", line 205, in load
    return backend.load(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)
  File "C:\Users\fenel\anaconda3\envs\d24_t1\lib\site-packages\torchaudio\_backend\soundfile.py", line 27, in load
    return soundfile_backend.load(uri, frame_offset, num_frames, normalize, channels_first, format)
  File "C:\Users\fenel\anaconda3\envs\d24_t1\lib\site-packages\torchaudio\_backend\soundfile_backend.py", line 221, in load
    with soundfile.SoundFile(filepath, "r") as file_:
  File "C:\Users\fenel\anaconda3\envs\d24_t1\lib\site-packages\soundfile.py", line 658, in __init__
    self._file = self._open(file, mode_int, closefd)
  File "C:\Users\fenel\anaconda3\envs\d24_t1\lib\site-packages\soundfile.py", line 1205, in _open
    file_ptr = openfunction(file, mode_int, self._info)
KeyboardInterrupt