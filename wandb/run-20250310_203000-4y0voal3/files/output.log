Original model structure:
Network_1(
  (quant): QuantStub()
  (dequant): DeQuantStub()
  (in_c): Sequential(
    (0): Conv2dNormActivation(
      (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (1): Conv2dNormActivation(
      (0): Conv2d(8, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
  )
  (stages): Sequential(
    (s1): Sequential(
      (b1): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
      (b2): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
      (b3): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential(
          (0): AvgPool2d(kernel_size=3, stride=(1, 2), padding=1)
          (1): Sequential()
        )
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 2), padding=(1, 1), groups=64, bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
    )
    (s2): Sequential(
      (b4): Block(
        (after_block_activation): ReLU()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), groups=64, bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(64, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
      (b5): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(56, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(120, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
    )
    (s3): Sequential(
      (b6): Block(
        (after_block_activation): ReLU()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(56, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(120, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
    )
  )
  (feed_forward): Sequential(
    (0): Conv2d(104, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): AdaptiveAvgPool2d(output_size=(1, 1))
  )
)
Before fusing, in_c module:
Sequential(
  (0): Conv2dNormActivation(
    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (1): Conv2dNormActivation(
    (0): Conv2d(8, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
)
Fusing in_c module index 0 with keys: ['0', '1', '2']
Fusing in_c module index 1 with keys: ['0', '1', '2']
Before fusing, block b1:
Block(
  (after_block_activation): ReLU()
  (shortcut): Sequential()
  (block): Sequential(
    (0): Conv2dNormActivation(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (1): Conv2dNormActivation(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (2): Conv2dNormActivation(
      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (ff): FloatFunctional(
    (activation_post_process): Identity()
  )
)
Fusing block b1 submodule 0 with keys: ['0', '1', '2']
Fusing block b1 submodule 1 with keys: ['0', '1', '2']
Fusing block b1 submodule 2 with keys: ['0', '1']
Before fusing, block b2:
Block(
  (after_block_activation): ReLU()
  (shortcut): Sequential()
  (block): Sequential(
    (0): Conv2dNormActivation(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (1): Conv2dNormActivation(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (2): Conv2dNormActivation(
      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (ff): FloatFunctional(
    (activation_post_process): Identity()
  )
)
Fusing block b2 submodule 0 with keys: ['0', '1', '2']
Fusing block b2 submodule 1 with keys: ['0', '1', '2']
Fusing block b2 submodule 2 with keys: ['0', '1']
Before fusing, block b3:
Block(
  (after_block_activation): ReLU()
  (shortcut): Sequential(
    (0): AvgPool2d(kernel_size=3, stride=(1, 2), padding=1)
    (1): Sequential()
  )
  (block): Sequential(
    (0): Conv2dNormActivation(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (1): Conv2dNormActivation(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 2), padding=(1, 1), groups=64, bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (2): Conv2dNormActivation(
      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (ff): FloatFunctional(
    (activation_post_process): Identity()
  )
)
Fusing block b3 submodule 0 with keys: ['0', '1', '2']
Fusing block b3 submodule 1 with keys: ['0', '1', '2']
Fusing block b3 submodule 2 with keys: ['0', '1']
Before fusing, block b4:
Block(
  (after_block_activation): ReLU()
  (block): Sequential(
    (0): Conv2dNormActivation(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (1): Conv2dNormActivation(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), groups=64, bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (2): Conv2dNormActivation(
      (0): Conv2d(64, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (ff): FloatFunctional(
    (activation_post_process): Identity()
  )
)
Fusing block b4 submodule 0 with keys: ['0', '1', '2']
Fusing block b4 submodule 1 with keys: ['0', '1', '2']
Fusing block b4 submodule 2 with keys: ['0', '1']
Before fusing, block b5:
Block(
  (after_block_activation): ReLU()
  (shortcut): Sequential()
  (block): Sequential(
    (0): Conv2dNormActivation(
      (0): Conv2d(56, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (1): Conv2dNormActivation(
      (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)
      (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (2): Conv2dNormActivation(
      (0): Conv2d(120, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (ff): FloatFunctional(
    (activation_post_process): Identity()
  )
)
Fusing block b5 submodule 0 with keys: ['0', '1', '2']
Fusing block b5 submodule 1 with keys: ['0', '1', '2']
Fusing block b5 submodule 2 with keys: ['0', '1']
Before fusing, block b6:
Block(
  (after_block_activation): ReLU()
  (block): Sequential(
    (0): Conv2dNormActivation(
      (0): Conv2d(56, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (1): Conv2dNormActivation(
      (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)
      (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (2): Conv2dNormActivation(
      (0): Conv2d(120, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (ff): FloatFunctional(
    (activation_post_process): Identity()
  )
)
Fusing block b6 submodule 0 with keys: ['0', '1', '2']
Fusing block b6 submodule 1 with keys: ['0', '1', '2']
Fusing block b6 submodule 2 with keys: ['0', '1']
After fusing, model structure:
Network_1(
  (quant): QuantStub()
  (dequant): DeQuantStub()
  (in_c): Sequential(
    (0): Conv2dNormActivation(
      (0): ConvReLU2d(
        (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): ReLU()
      )
      (1): Identity()
      (2): Identity()
    )
    (1): Conv2dNormActivation(
      (0): ConvReLU2d(
        (0): Conv2d(8, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): ReLU()
      )
      (1): Identity()
      (2): Identity()
    )
  )
  (stages): Sequential(
    (s1): Sequential(
      (b1): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
            (1): Identity()
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
      (b2): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
            (1): Identity()
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
      (b3): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential(
          (0): AvgPool2d(kernel_size=3, stride=(1, 2), padding=1)
          (1): Sequential()
        )
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 2), padding=(1, 1), groups=64)
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
            (1): Identity()
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
    )
    (s2): Sequential(
      (b4): Block(
        (after_block_activation): ReLU()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), groups=64)
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(64, 56, kernel_size=(1, 1), stride=(1, 1))
            (1): Identity()
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
      (b5): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(56, 120, kernel_size=(1, 1), stride=(1, 1))
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120)
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(120, 56, kernel_size=(1, 1), stride=(1, 1))
            (1): Identity()
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
    )
    (s3): Sequential(
      (b6): Block(
        (after_block_activation): ReLU()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(56, 120, kernel_size=(1, 1), stride=(1, 1))
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): ConvReLU2d(
              (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120)
              (1): ReLU()
            )
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(120, 104, kernel_size=(1, 1), stride=(1, 1))
            (1): Identity()
          )
        )
        (ff): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
    )
  )
  (feed_forward): Sequential(
    (0): Conv2d(104, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): AdaptiveAvgPool2d(output_size=(1, 1))
  )
)
Starting QAT training...
Epoch [1/5], Loss: 2.6171
Epoch [2/5], Loss: 2.2220
Epoch [3/5], Loss: 2.1412
Epoch [4/5], Loss: 2.0708
Epoch [5/5], Loss: 2.0057
Quantized model:
Network_1(
  (quant): Quantize(scale=tensor([0.1847]), zero_point=tensor([62]), dtype=torch.quint8)
  (dequant): DeQuantize()
  (in_c): Sequential(
    (0): Conv2dNormActivation(
      (0): QuantizedConvReLU2d(1, 8, kernel_size=(3, 3), stride=(2, 2), scale=0.07876265048980713, zero_point=0, padding=(1, 1))
      (1): Identity()
      (2): Identity()
    )
    (1): Conv2dNormActivation(
      (0): QuantizedConvReLU2d(8, 32, kernel_size=(3, 3), stride=(2, 2), scale=0.07906799018383026, zero_point=0, padding=(1, 1))
      (1): Identity()
      (2): Identity()
    )
  )
  (stages): Sequential(
    (s1): Sequential(
      (b1): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(32, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.13042357563972473, zero_point=0)
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.13233454525470734, zero_point=0, padding=(1, 1), groups=64)
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): QuantizedConv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), scale=0.21122519671916962, zero_point=64)
            (1): Identity()
          )
        )
        (ff): QFunctional(
          scale=0.23649749159812927, zero_point=55
          (activation_post_process): Identity()
        )
      )
      (b2): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(32, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.1450110524892807, zero_point=0)
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.17552684247493744, zero_point=0, padding=(1, 1), groups=64)
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): QuantizedConv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), scale=0.30895888805389404, zero_point=60)
            (1): Identity()
          )
        )
        (ff): QFunctional(
          scale=0.30783215165138245, zero_point=53
          (activation_post_process): Identity()
        )
      )
      (b3): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential(
          (0): AvgPool2d(kernel_size=3, stride=(1, 2), padding=1)
          (1): Sequential()
        )
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(32, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.14196743071079254, zero_point=0)
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 2), scale=0.15788893401622772, zero_point=0, padding=(1, 1), groups=64)
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): QuantizedConv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), scale=0.22108688950538635, zero_point=56)
            (1): Identity()
          )
        )
        (ff): QFunctional(
          scale=0.3033355176448822, zero_point=35
          (activation_post_process): Identity()
        )
      )
    )
    (s2): Sequential(
      (b4): Block(
        (after_block_activation): ReLU()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(32, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.17652912437915802, zero_point=0)
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(2, 1), scale=0.2133561372756958, zero_point=0, padding=(1, 1), groups=64)
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): QuantizedConv2d(64, 56, kernel_size=(1, 1), stride=(1, 1), scale=0.25282353162765503, zero_point=70)
            (1): Identity()
          )
        )
        (ff): QFunctional(
          scale=1.0, zero_point=0
          (activation_post_process): Identity()
        )
      )
      (b5): Block(
        (after_block_activation): ReLU()
        (shortcut): Sequential()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(56, 120, kernel_size=(1, 1), stride=(1, 1), scale=0.17728084325790405, zero_point=0)
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(120, 120, kernel_size=(3, 3), stride=(1, 1), scale=0.1893925964832306, zero_point=0, padding=(1, 1), groups=120)
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): QuantizedConv2d(120, 56, kernel_size=(1, 1), stride=(1, 1), scale=0.27914607524871826, zero_point=69)
            (1): Identity()
          )
        )
        (ff): QFunctional(
          scale=0.28050705790519714, zero_point=55
          (activation_post_process): Identity()
        )
      )
    )
    (s3): Sequential(
      (b6): Block(
        (after_block_activation): ReLU()
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(56, 120, kernel_size=(1, 1), stride=(1, 1), scale=0.18415862321853638, zero_point=0)
            (1): Identity()
            (2): Identity()
          )
          (1): Conv2dNormActivation(
            (0): QuantizedConvReLU2d(120, 120, kernel_size=(3, 3), stride=(1, 1), scale=0.36408987641334534, zero_point=0, padding=(1, 1), groups=120)
            (1): Identity()
            (2): Identity()
          )
          (2): Conv2dNormActivation(
            (0): QuantizedConv2d(120, 104, kernel_size=(1, 1), stride=(1, 1), scale=0.3794270157814026, zero_point=69)
            (1): Identity()
          )
        )
        (ff): QFunctional(
          scale=1.0, zero_point=0
          (activation_post_process): Identity()
        )
      )
    )
  )
  (feed_forward): Sequential(
    (0): QuantizedConv2d(104, 10, kernel_size=(1, 1), stride=(1, 1), scale=0.9111436009407043, zero_point=49, bias=False)
    (1): QuantizedBatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): AdaptiveAvgPool2d(output_size=(1, 1))
  )
)










































































































































Batch: 32/116 -- Batch Accuracy: 111/256
Traceback (most recent call last):
  File "c:\Users\fenel\Documents\dcase2024_task1_baseline\qat_1.py", line 446, in <module>
    main()
  File "c:\Users\fenel\Documents\dcase2024_task1_baseline\qat_1.py", line 423, in main
    unquantized_accuracy = evaluate(model_unquantized, test_loader, MelSpecGenerator)
  File "c:\Users\fenel\Documents\dcase2024_task1_baseline\qat_1.py", line 318, in evaluate
    for idx, batch in enumerate(dataloader):
  File "C:\Users\fenel\anaconda3\envs\d24_t1\lib\site-packages\torch\utils\data\dataloader.py", line 630, in __next__
    data = self._next_data()
  File "C:\Users\fenel\anaconda3\envs\d24_t1\lib\site-packages\torch\utils\data\dataloader.py", line 673, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
KeyboardInterrupt